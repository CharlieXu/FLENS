=====
FLENS                                                                   [TOC]
=====

FLENS is short for _Flexible Library for Efficient Numerical Solutions_.  And
that's exactly what it is:

*A builing block for the implementation of other (higher-level) numerical
libraries or numerical applications*

This site is about a working branch that is focused on the __FLENS-LAPACK__ part
of FLENS.  In the past FLENS only had a interface/binding to __LAPACK__.  Now
we show how FLENS can be used to implement LAPACK in C++.  Of course it should
produce the same results, run at the same speed and it should be easier to
impelment a LAPACK routine with FLENS than with Fortran.

Here we show how far we got right now ...


What you should read
====================

As the documentation is almost not existing you don't have much to read.  This
is what we can offer you at the moment:

- Looking at examples is always a good start:
    - Computing a __LU factorization__,
    - computing a __QR factorization__,
    - computing __eigenvalues and eigenvectors__,
    - solving __systems of linear equations__.
- Overview of all driver functions currently implemented in __FLENS-LAPACK__
- We just started with a __tutorial__:
    - Session 1: First steps with general matrices.
    - Session 2: Triangular and symmetric matrices.

From the examples you also can see what compiler flags are needed.


Scope of this Branch
====================

- Only real matrix types with full storage and dense vector types, i.e.
    - __GeMatrix__,
    - __SyMatrix__,
    - __TrMatrix__,
    - __DenseVector__.
- Our generic BLAS implementation __CXXBLAS__.
- Support for high and multipecission types from __QD Library__ and __mpfr__.
- Support for native BLAS implementations like __ATLAS__ or __GotoBLAS__.
- Overloaded operators for BLAS mostly work but are not well tested.
  In FLENS-LAPACK we use the __FLENS-BLAS__ layer (e.g. blas::mv) which
  is for the LAPACK part often more expressive.
- We improved our *doctool* (look at the bottom of each page for *document
  source*).  We now use *restructured text*.


Compiler Requirements
=====================
FLENS uses some of the C++11 features and therefore requires a recent C++
compiler:

  - __clang__ version 3.0 (or higher)
  - __gcc__ version 4.7 (or higher)
  - __icc__ version 12.1.2 (or higher)


Git It
======

You can clone a public branch from __GitHub__

  *--[BOX]------------------------------------------------------------------*
  |                                                                         |
  |  git clone git://github.com/michael-lehn/FLENS.git                      |
  |                                                                         |
  *-------------------------------------------------------------------------*

Philosophy
==========

  *--[BOX]------------------------------------------------------------------*
  |                                                                         |
  |  We are *FLENS*.                                                        |
  |                                                                         |
  |  Resistance is futile.                                                  |
  |                                                                         |
  |  Advanced technology will be assimilated...                             |
  |                                                                         |
  *-------------------------------------------------------------------------*

  This should answer the following questions:

  - Why are the matrix/vector types in FLENS as they are?
  - Why do we reimplement the LAPACK library with FLENS?
  - What is the idea behind our CXXBLAS?

  The answer is simple:

  - LAPACK is the most advanced and best supported numerical library in the
    world.  Improvements in numerical algorithms have a great chance to make
    it soon into LAPACK.  If we keep FLENS-LAPACK up-to-date to current LAPACK
    releases we keep up with some of the most sophisticated numerical
    algorithms.
  - LAPACK gains its performance from highly optimized BLAS kernel routines.
    These implementations achieve peak performance on certain platforms.
    When possible our CXXBLAS is just an interface to these implementations.
  - For multi-precision data types CXXBLAS gives you a generic implementation
    that does not give high performance (yet) but allows using LAPACK in
    high precision.


Mailing List
============

Join the mailing __list__!


:links: __FLENS-LAPACK__ -> doc:flens/lapack/lapack
        __LAPACK__       -> http://www.netlib.org/lapack/
        __systems of linear equations__   -> doc:flens/examples/lapack-gesv
        __LU factorization__              -> doc:flens/examples/lapack-getrf
        __QR factorization__              -> doc:flens/examples/lapack-geqrf
        __eigenvalues and eigenvectors__  -> doc:flens/examples/lapack-geev
        __tutorial__    -> doc:flens/examples/tutorial
        __GeMatrix__    -> file:flens/matrixtypes/general/impl/gematrix.h
        __SyMatrix__    -> file:flens/matrixtypes/symmetric/impl/symatrix.h
        __TrMatrix__    -> file:flens/matrixtypes/triangular/impl/trmatrix.h
        __DenseVector__ -> file:flens/vectortypes/impl/densevector.h
        __CXXBLAS__     -> dir:cxxblas/
        __QD Library__  -> http://crd-legacy.lbl.gov/~dhbailey/mpdist
        __mpfr__        -> http://www.mpfr.org
        __ATLAS__       -> http://math-atlas.sourceforge.net
        __GotoBLAS__    -> http://www.tacc.utexas.edu/tacc-projects/gotoblas2
        __FLENS-BLAS__  -> dir:flens/blas/
        __GitHub__      -> http://github.com/michael-lehn/FLENS
        __clang__       -> http://clang.llvm.org/
        __gcc__         -> http://gcc.gnu.org/
        __icc__         -> http://software.intel.com/en-us/articles/intel-compilers/
        __list__        -> https://imap.uni-ulm.de/lists/info/flens

