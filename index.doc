===============
FLENS (Trinity)                                                         [TOC]
===============

FLENS is a C++ library that defines matrix/vector types for numerical linear
algebra and high performance computing.

Purpose
=======
One of the most successful and relevant libraries in the field of numerical
linear algebra is LAPACK which is implemented in Fortran 77.  So a *necessary
conditions* for FLENS being a useful numerical linear algebra are:

  - *It has to be possible to re-implement LAPACK with FLENS.*

    Furthermore, the implementation has to be at least as easy-to-accomplish,
    expressive, readable and maintainable for experts in this field.

  - *This reimplementation must provide the same accuracy as the original
    LAPACK.*

    In the C++ community many people underestimate how much effort is spent in
    LAPACK on numerical stability and accuracy.  This goes far beyond school
    book methods and _numerical recipies_.  At the same time high performance
    gets achieved at the level of peak performance.

  - *Transparency*

    Never ever create implicitly a temporary vector or matrix.  If an operation
    would require a temporary it ideally triggers a compile  time error but at
    least an assertion failure at runtime.

    It always must be clear what computational back end gets used to carry out
    a linear algebra operation (e.g. matrix-vector or matrix-matrix products).
    A linear algebra expression coded with overloaded operators must be
    equivalent to a sequence of explicit function calls. No magic!

  - *There must be no runtime overhead compared to the Fortran implementation.*

    An implementation with FLENS must provide the same performance as a
    dedicated, hand-coded implementation in C or Fortran.

Only if these conditions are fully met, further benefits will matter.  Some
benefits that *make FLENS/C++ more favorable than using Fortran* are:

  - *Ease-of-use for people doing numerical linear algebra.*

    We are dealing with matrices and vectors in the context of numerical linear
    algebra.  So we want to remind some C++ folks that these are not containers
    like for instance `std::vector`.

    So ease-of-use for containers and ease-of-use for matrices/vectors are two
    different things.  For containers iterators are great.  For matrices they
    are not.

  - *Ease-of-use and type safety for common tasks in numerical linear algebra.*

    One of the most crucial tasks is working with matrix/vector views.  These
    are matrices or vectors that reference elements from another matrix or
    vector.  Some more concrete examples of common cases are:

      - Matrix views referencing elements from a vector or raw C array buffer.
      - The same junk of data can be referred as a general matrix, symmetric,
        hermitian or triangular matrix.  Using corresponding matrix view types
        one statically tags the memory for its intended usage.  In a numerical
        algorithm it is not uncommon that you first want to the same data first
        as a general matrix, then as a lower triangular matrix and finally as
        a upper triangular matrix.  So using matrix view types makes it possible
        to check whether accessing elements on the upper triangular is legal or
        not.  And by the way: No, if you have a lower triangular matrix and
        you access an element from the upper triangular part you do not get a
        zero.  Instead you get an assertion failure as you deserve because your
        algorithm does not exploit this special case.  And FLENS is not
        responsible to optimize your flawed algorithm.
      - Matrices can be col major or row major.  Referencing contiguous
        rectangular blocks leads to matrix views that are again col or row
        major.  Starting with Trinity, in FLENS we also support matrix views
        that, e.g., reference every second row and every third column of a
        matrix.  These so called *grid views* can be used like a regular matrix
        but its elements are located neither in row or column major order.
        Efficiency for these kind of views can be provided through BLAS kernels
        like *ulmBLAS* or *BLIS*.

  - *We want to optimize two aspects:*

      - *User aspect:* Using the resulting FLENS-LAPACK should be easier than
        using LAPACK directly.
      - *Developer aspect:* It should be easier to develop something like LAPACK
        with C++/FLENS than with Fortran.  Note that developing something like
        LAPACK requires quite some mathematical background that many people
        underestimate.  If you don't have this background and want to develop
        high performance numerical software you have to study some textbooks
        first.

Being able to re-implement LAPACK efficiently with FLENS is just one application
to prove and benchmark its concepts.  But FLENS should be considered a building
block for numerical linear algebra. It extends the scope of C++ for features
that are necessary for doing numerical linear algebra.  That means it is
possible to also realize new approaches in this field.  For example realizing
ideas from Plasma, Magma, etc.


Examples and Tutorial
=====================

+------------------+-----------------------------------------------------------+
| __Session 1__    | - First steps with general matrices and dense vectors.    |
|                  | - Idea of dividing matrix/vectors into matrix/vector      |
|                  |   types and storage schemes.                              |
|                  | - Notation for element Access and retrieving matrix/vector|
|                  |   dimensions.                                             |
|                  | - Retriving strides and pointers to raw data.             |
|                  | - What are matrix/vector views? How to create and use     |
|                  |   them?                                                   |
|                  | - Triangular/trapezoidal, symmetric and hermitian         |
|                  |   matrices.                                               |
|                  | - General, triangular/trapezoidal, symmetric and hermitian|
|                  |   matrix-views.                                           |
+------------------+-----------------------------------------------------------+
| __Session 2__    | - Basic linear agrbra operations, e.g. vector sums, matrix|
|                  |   products, etc.                                          |
|                  | - Using the low-level C++ BLAS interface (__CXXBLAS__).   |
|                  | - Using the high-level BLAS interface (__FLENS-BLAS__).   |
|                  | - Using overloaded operators.                             |
|                  | - What overloaded operators *must not* allow in a library |
|                  |   for high performance computing.                         |
+------------------+-----------------------------------------------------------+
| __Session 3__    | - Examples for using FLENS-LAPACK.                        |
|                  | - Howto implement a high performance LU factorization.    |
+------------------+-----------------------------------------------------------+
| __CXXBLAS__      | Overview of the low-level C++ BLAS interface              |
+------------------+-----------------------------------------------------------+
| __FLENS-BLAS__   | Overview of the high-level FLENS-BLAS interface           |
+------------------+-----------------------------------------------------------+
| __FLENS-LAPACK__ | Overview of some LAPACK driver functions we re-implemented|
|                  | with C++/FLENS.                                           |
+------------------+-----------------------------------------------------------+



# - __Session 2__: BLAS, CXXBLAS, FLENS-BLAS and Overloaded Operators.
# - __Session 3__: More on matrices: Triangular and symmetric matrices,
#   matrix views, ...
# - __Session 4__: Using FLENS-LAPACK.
# - __Session 5__: Using an external LAPACK implementation.
# - __Session 6__: Sparse Matrices (_Experimental_).
# - __Session 7__: User Defined Matrix Types.
# - Overview of all driver functions currently implemented in __FLENS-LAPACK__


Features
========
- C++ library (requires a C++11 conform compiler)
- Easy install as FLENS is _headers only_
- FLENS gives you
    - Matrix/vector types for dense linear algebra
    - Low-level C++ interface to __BLAS__ (see __CXXBLAS__).
    - High-level interface to __BLAS__ (see __FLENS-BLAS__).
    - Reimplementation of __LAPACK__ (see __FLENS-LAPACK__)
    - __CXXBLAS__, __FLENS-BLAS__ and __FLENS-LAPACK__ support types from the
      __QD Library__ and  __mpfr__.
- Starting with Trinity by default FLENS uses ulmBLAS as default computational
  BLAS back end.  Alternatively you can use other BLAS back ends, e.g.
    - Compile with `-DWITH_ATLAS` and link against __ATLAS__.
    - Compile with `-DWITH_GOTOBLAS` and link against __GotoBLAS__.
    - ...
- FLENS also allows to use overloaded operators for __BLAS__ operations.  Most
  important in this respect:
    - Overloaded operators come without performance penalty!
    - In a special debug mode you can exactly trace what is happening and
      how you linear algebra expressions gets evaluated through BLAS
      calls
    - More features are explained in the __tutorial__.



Compiler Requirements
=====================
FLENS uses some of the C++11 features and therefore requires a recent C++
compiler:

  - __clang__ version 3.0 (or higher)
  - __gcc__ version 4.7 (or higher)
  - __icc__ version 12.1.2 (or higher)


Obtain FLENS (Trinity)
======================
You can clone the Trinity branch from __GitHub__

  *--[BOX]----------------------------------------------------------------------*
  |                                                                             |
  |  git clone --recursive -b Trinity https://github.com/michael-lehn/FLENS.git |
  |                                                                             |
  *-----------------------------------------------------------------------------*


Mailing List
============

Join the mailing __list__!

Contributors
============
- Iris Häcker
- Michael Lehn
- Klaus Pototzky
- Alexander Stippler


:links: __FLENS-LAPACK__ -> doc:flens/lapack/lapack
        __FLENS-BLAS__   -> doc:flens/blas/blas
        __BLAS__         -> http://www.netlib.org/blas/
        __LAPACK__       -> http://www.netlib.org/lapack/
        __tutorial__     -> doc:flens/examples/tutorial
        __Session (\d)__ -> doc:flens/examples/tutorial#$1
        __CXXBLAS__      -> dir:ulmblas/cxxblas/
        __QD Library__   -> http://crd-legacy.lbl.gov/~dhbailey/mpdist
        __mpfr__         -> http://www.mpfr.org
        __ATLAS__        -> http://math-atlas.sourceforge.net
        __GotoBLAS__     -> http://www.tacc.utexas.edu/tacc-projects/gotoblas2
        __GitHub__       -> http://github.com/michael-lehn/FLENS
        __clang__        -> http://clang.llvm.org/
        __gcc__          -> http://gcc.gnu.org/
        __icc__          -> http://software.intel.com/en-us/articles/intel-compilers/
        __list__         -> https://imap.uni-ulm.de/lists/info/flens

